{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11800147,"sourceType":"datasetVersion","datasetId":7410341}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**BLIP Fine-tuning**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n!tar -xf abo-images-small.tar\n!rm abo-images-small.tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:03:19.887270Z","iopub.execute_input":"2025-05-11T07:03:19.888072Z","iopub.status.idle":"2025-05-11T07:04:51.805753Z","shell.execute_reply.started":"2025-05-11T07:03:19.888035Z","shell.execute_reply":"2025-05-11T07:04:51.804345Z"}},"outputs":[{"name":"stdout","text":"--2025-05-11 07:03:19--  https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\nResolving amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)... 16.182.108.241, 3.5.10.150, 3.5.2.206, ...\nConnecting to amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)|16.182.108.241|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3253381120 (3.0G) [application/x-tar]\nSaving to: ‘abo-images-small.tar’\n\nabo-images-small.ta 100%[===================>]   3.03G  47.2MB/s    in 66s     \n\n2025-05-11 07:04:26 (46.9 MB/s) - ‘abo-images-small.tar’ saved [3253381120/3253381120]\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pickle\nimport shutil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:03:02.734668Z","iopub.execute_input":"2025-05-11T07:03:02.734878Z","iopub.status.idle":"2025-05-11T07:03:02.738971Z","shell.execute_reply.started":"2025-05-11T07:03:02.734861Z","shell.execute_reply":"2025-05-11T07:03:02.738442Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\nwith open(\"/kaggle/input/amazon-berkley-vqa/train.json\", \"r\") as f:\n    questions_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:03:02.740290Z","iopub.execute_input":"2025-05-11T07:03:02.740485Z","iopub.status.idle":"2025-05-11T07:03:02.843848Z","shell.execute_reply.started":"2025-05-11T07:03:02.740469Z","shell.execute_reply":"2025-05-11T07:03:02.843213Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:03:02.844573Z","iopub.execute_input":"2025-05-11T07:03:02.844827Z","iopub.status.idle":"2025-05-11T07:03:02.855951Z","shell.execute_reply.started":"2025-05-11T07:03:02.844807Z","shell.execute_reply":"2025-05-11T07:03:02.855287Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"all_entries = []\nfor img_path, qas in list(questions_data.items()):\n    for qa in qas:\n        all_entries.append({\n            \"image_path\": img_path,\n            \"question\": qa[\"question\"],\n            \"answer\": qa[\"answer\"]\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:03:02.856781Z","iopub.execute_input":"2025-05-11T07:03:02.857252Z","iopub.status.idle":"2025-05-11T07:03:02.899331Z","shell.execute_reply.started":"2025-05-11T07:03:02.857226Z","shell.execute_reply":"2025-05-11T07:03:02.898788Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data, val_data = train_test_split(all_entries, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:04:55.730837Z","iopub.execute_input":"2025-05-11T07:04:55.731141Z","iopub.status.idle":"2025-05-11T07:04:55.745333Z","shell.execute_reply.started":"2025-05-11T07:04:55.731115Z","shell.execute_reply":"2025-05-11T07:04:55.744805Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CustomVQADataset(Dataset):\n    def __init__(self, data, processor):\n        self.data = data\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        image = Image.open(item[\"image_path\"]).convert(\"RGB\")\n        question = item[\"question\"]\n        answer = item[\"answer\"].lower()\n\n        # Process the image and question\n        encoding = self.processor(image, question, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        labels = self.processor.tokenizer.encode(answer, max_length=8, padding=\"max_length\", truncation=True, return_tensors='pt')\n\n        encoding[\"labels\"] = labels\n        for k, v in encoding.items():\n            encoding[k] = v.squeeze(0)\n\n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:04:58.605542Z","iopub.execute_input":"2025-05-11T07:04:58.606071Z","iopub.status.idle":"2025-05-11T07:04:58.611730Z","shell.execute_reply.started":"2025-05-11T07:04:58.606041Z","shell.execute_reply":"2025-05-11T07:04:58.611125Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nbase_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# Apply LoRA\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n)\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:05:00.984460Z","iopub.execute_input":"2025-05-11T07:05:00.985212Z","iopub.status.idle":"2025-05-11T07:05:09.990292Z","shell.execute_reply.started":"2025-05-11T07:05:00.985186Z","shell.execute_reply":"2025-05-11T07:05:09.989614Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c54b4d7cabc84e91b25c12a0056e888b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c516c9902e47f18394d47b286b1523"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29e0249b08e4278929c30758c090c81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"819eff8131c94c8cbafe186c5b205211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92fc0ba681f44e9a92f4212e38609924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00cdd378709340829d779877167d247e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf4c9f0a2d34ea49f410c103a645be2"}},"metadata":{}},{"name":"stdout","text":"trainable params: 1,179,648 || all params: 385,852,220 || trainable%: 0.3057\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train_dataset = CustomVQADataset(train_data, processor)\nval_dataset = CustomVQADataset(val_data, processor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=12, shuffle=False, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:05:12.014934Z","iopub.execute_input":"2025-05-11T07:05:12.015749Z","iopub.status.idle":"2025-05-11T07:05:12.020149Z","shell.execute_reply.started":"2025-05-11T07:05:12.015722Z","shell.execute_reply":"2025-05-11T07:05:12.019411Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.nn.DataParallel(model)\nmodel.to(device)\n\n# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\nscaler = torch.cuda.amp.GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:05:13.537595Z","iopub.execute_input":"2025-05-11T07:05:13.537897Z","iopub.status.idle":"2025-05-11T07:05:14.462365Z","shell.execute_reply.started":"2025-05-11T07:05:13.537873Z","shell.execute_reply":"2025-05-11T07:05:14.461425Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3044266455.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"num_epochs = 30\npatience = 3\nmin_eval_loss = float(\"inf\")\nearly_stopping = 0\ntracking = []\n\nfor epoch in range(1, num_epochs):\n    model.train()\n    train_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n        input_ids = batch['input_ids'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(input_ids=input_ids,\n                            pixel_values=pixel_values,\n                            attention_mask=attention_mask,\n                            labels=labels)\n        loss = outputs.loss\n        if loss.ndim > 0:\n            loss = loss.mean() \n        train_loss += loss.item()\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Validating\"):\n            input_ids = batch['input_ids'].to(device)\n            pixel_values = batch['pixel_values'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = model(input_ids=input_ids,\n                                pixel_values=pixel_values,\n                                attention_mask=attention_mask,\n                                labels=labels)\n            loss = outputs.loss\n            if loss.ndim > 0:\n                loss = loss.mean() \n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(val_loader)\n    tracking.append((train_loss, val_loss))\n\n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n\n    # Early stopping\n    if val_loss < min_eval_loss:\n        min_eval_loss = val_loss\n        early_stopping = 0\n        model.module.save_pretrained(\"blip-lora-vqa\")\n        shutil.make_archive(\"blip-lora-vqa\", 'zip', \"blip-lora-vqa\")\n        print(\"Saved best model.\")\n    else:\n        early_stopping += 1\n        if early_stopping >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    scheduler.step()\n\nwith open(\"training_tracking.pkl\", \"wb\") as f:\n    pickle.dump(tracking, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T08:02:38.571379Z","iopub.execute_input":"2025-05-11T08:02:38.571663Z","iopub.status.idle":"2025-05-11T13:47:38.809555Z","shell.execute_reply.started":"2025-05-11T08:02:38.571640Z","shell.execute_reply":"2025-05-11T13:47:38.808124Z"}},"outputs":[{"name":"stderr","text":"Epoch 2 Training: 100%|██████████| 2035/2035 [33:20<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:53<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 6.2358 | Val Loss: 6.2116\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Training: 100%|██████████| 2035/2035 [33:21<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:54<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 6.1939 | Val Loss: 6.1959\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Training: 100%|██████████| 2035/2035 [33:17<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:52<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 6.1755 | Val Loss: 6.1905\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 Training: 100%|██████████| 2035/2035 [33:20<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:53<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 6.1629 | Val Loss: 6.1859\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 Training: 100%|██████████| 2035/2035 [33:16<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:53<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 6.1531 | Val Loss: 6.1846\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 Training: 100%|██████████| 2035/2035 [33:19<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:53<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 6.1447 | Val Loss: 6.1826\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 Training: 100%|██████████| 2035/2035 [33:17<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:54<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 6.1375 | Val Loss: 6.1820\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 Training: 100%|██████████| 2035/2035 [33:13<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:53<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 6.1312 | Val Loss: 6.1834\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 Training: 100%|██████████| 2035/2035 [33:13<00:00,  1.02it/s]\nValidating: 100%|██████████| 509/509 [04:52<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 6.1261 | Val Loss: 6.1821\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 Training:   4%|▍         | 77/2035 [01:15<32:01,  1.02it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2616035670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1035136874.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Process the image and question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, padding_side, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m                 method).\n\u001b[1;32m   2653\u001b[0m         \"\"\"\n\u001b[0;32m-> 2654\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2655\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         )\n\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3073\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3074\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     ) -> BatchEncoding:\n\u001b[1;32m    612\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    614\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eventual_warn_about_too_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitized_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     def _encode_plus(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0;31m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtensor_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJAX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"model.module.save_pretrained(\"blip-lora-vqa\")\nprint(\"Saved best model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T07:51:17.146861Z","iopub.execute_input":"2025-05-11T07:51:17.147703Z","iopub.status.idle":"2025-05-11T07:51:17.581012Z","shell.execute_reply.started":"2025-05-11T07:51:17.147674Z","shell.execute_reply":"2025-05-11T07:51:17.580325Z"}},"outputs":[{"name":"stdout","text":"Saved best model.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**Different configuration**","metadata":{}},{"cell_type":"code","source":"!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n!tar -xf abo-images-small.tar\n!rm abo-images-small.tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:42:17.852151Z","iopub.execute_input":"2025-05-13T19:42:17.852412Z","iopub.status.idle":"2025-05-13T19:44:25.304853Z","shell.execute_reply.started":"2025-05-13T19:42:17.852393Z","shell.execute_reply":"2025-05-13T19:44:25.303759Z"}},"outputs":[{"name":"stdout","text":"--2025-05-13 19:42:17--  https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\nResolving amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)... 54.231.232.161, 52.217.161.217, 52.217.142.89, ...\nConnecting to amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)|54.231.232.161|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3253381120 (3.0G) [application/x-tar]\nSaving to: ‘abo-images-small.tar’\n\nabo-images-small.ta 100%[===================>]   3.03G  36.2MB/s    in 94s     \n\n2025-05-13 19:43:52 (32.9 MB/s) - ‘abo-images-small.tar’ saved [3253381120/3253381120]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pickle\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:46:44.593031Z","iopub.execute_input":"2025-05-13T19:46:44.593926Z","iopub.status.idle":"2025-05-13T19:47:08.328149Z","shell.execute_reply.started":"2025-05-13T19:46:44.593889Z","shell.execute_reply":"2025-05-13T19:47:08.327388Z"}},"outputs":[{"name":"stderr","text":"2025-05-13 19:46:55.958800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747165616.161118      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747165616.221528      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"with open(\"/kaggle/input/train-data/train.json\", \"r\") as f:\n    questions_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:25.398077Z","iopub.execute_input":"2025-05-17T14:35:25.398642Z","iopub.status.idle":"2025-05-17T14:35:25.447825Z","shell.execute_reply.started":"2025-05-17T14:35:25.398615Z","shell.execute_reply":"2025-05-17T14:35:25.446901Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:26.047544Z","iopub.execute_input":"2025-05-17T14:35:26.047854Z","iopub.status.idle":"2025-05-17T14:35:26.053626Z","shell.execute_reply.started":"2025-05-17T14:35:26.047831Z","shell.execute_reply":"2025-05-17T14:35:26.052894Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"all_entries = []\nfor img_path, qas in list(questions_data.items()):\n    for qa in qas:\n        all_entries.append({\n            \"image_path\": img_path,\n            \"question\": qa[\"question\"],\n            \"answer\": qa[\"answer\"]\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:26.697255Z","iopub.execute_input":"2025-05-17T14:35:26.697588Z","iopub.status.idle":"2025-05-17T14:35:26.723800Z","shell.execute_reply.started":"2025-05-17T14:35:26.697562Z","shell.execute_reply":"2025-05-17T14:35:26.722994Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_data, val_data = train_test_split(all_entries, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:27.885607Z","iopub.execute_input":"2025-05-17T14:35:27.885887Z","iopub.status.idle":"2025-05-17T14:35:27.900255Z","shell.execute_reply.started":"2025-05-17T14:35:27.885868Z","shell.execute_reply":"2025-05-17T14:35:27.899278Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"class CustomVQADataset(Dataset):\n    def __init__(self, data, processor):\n        self.data = data\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        image = Image.open(item[\"image_path\"]).convert(\"RGB\")\n        question = item[\"question\"]\n        answer = item[\"answer\"].lower()\n\n        # Process the image and question\n        encoding = self.processor(image, question, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        labels = self.processor.tokenizer.encode(answer, max_length=8, padding=\"max_length\", truncation=True, return_tensors='pt')\n\n        encoding[\"labels\"] = labels\n        for k, v in encoding.items():\n            encoding[k] = v.squeeze(0)\n\n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:29.495130Z","iopub.execute_input":"2025-05-17T14:35:29.496168Z","iopub.status.idle":"2025-05-17T14:35:29.502636Z","shell.execute_reply.started":"2025-05-17T14:35:29.496127Z","shell.execute_reply":"2025-05-17T14:35:29.501670Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nbase_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# Apply LoRA\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=0.2,\n    bias=\"none\",\n)\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:34.779747Z","iopub.execute_input":"2025-05-17T14:35:34.780043Z","iopub.status.idle":"2025-05-17T14:35:36.721619Z","shell.execute_reply.started":"2025-05-17T14:35:34.780020Z","shell.execute_reply":"2025-05-17T14:35:36.720877Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,359,296 || all params: 387,031,868 || trainable%: 0.6096\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"train_dataset = CustomVQADataset(train_data, processor)\nval_dataset = CustomVQADataset(val_data, processor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=12, shuffle=False, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:41.046621Z","iopub.execute_input":"2025-05-17T14:35:41.046940Z","iopub.status.idle":"2025-05-17T14:35:41.072189Z","shell.execute_reply.started":"2025-05-17T14:35:41.046916Z","shell.execute_reply":"2025-05-17T14:35:41.071241Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.nn.DataParallel(model)\nmodel.to(device)\n\n# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\nscaler = torch.cuda.amp.GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:42.821120Z","iopub.execute_input":"2025-05-17T14:35:42.821416Z","iopub.status.idle":"2025-05-17T14:35:43.573789Z","shell.execute_reply.started":"2025-05-17T14:35:42.821397Z","shell.execute_reply":"2025-05-17T14:35:43.572838Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3044266455.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"num_epochs = 30\npatience = 3\nmin_eval_loss = float(\"inf\")\nearly_stopping = 0\ntracking = []\n\nfor epoch in range(1, num_epochs):\n    model.train()\n    train_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n        input_ids = batch['input_ids'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(input_ids=input_ids,\n                            pixel_values=pixel_values,\n                            attention_mask=attention_mask,\n                            labels=labels)\n        loss = outputs.loss\n        if loss.ndim > 0:\n            loss = loss.mean() \n        train_loss += loss.item()\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Validating\"):\n            input_ids = batch['input_ids'].to(device)\n            pixel_values = batch['pixel_values'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = model(input_ids=input_ids,\n                                pixel_values=pixel_values,\n                                attention_mask=attention_mask,\n                                labels=labels)\n            loss = outputs.loss\n            if loss.ndim > 0:\n                loss = loss.mean() \n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(val_loader)\n    tracking.append((train_loss, val_loss))\n\n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n\n    # Early stopping\n    if val_loss < min_eval_loss:\n        min_eval_loss = val_loss\n        early_stopping = 0\n        model.module.save_pretrained(\"blip-lora-vqa\")\n        shutil.make_archive(\"blip-lora-vqa\", 'zip', \"blip-lora-vqa\")\n        print(\"Saved best model.\")\n    else:\n        early_stopping += 1\n        if early_stopping >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    scheduler.step()\n\nwith open(\"training_tracking.pkl\", \"wb\") as f:\n    pickle.dump(tracking, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:35:47.358842Z","iopub.execute_input":"2025-05-17T14:35:47.359161Z","iopub.status.idle":"2025-05-17T14:36:01.884687Z","shell.execute_reply.started":"2025-05-17T14:35:47.359119Z","shell.execute_reply":"2025-05-17T14:36:01.880792Z"}},"outputs":[{"name":"stderr","text":"Epoch 2 Training:   1%|          | 13/2035 [00:14<37:26,  1.11s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2616035670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             outputs = model(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     19\u001b[0m                             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     ) -> List[Any]:\n\u001b[0;32m--> 212\u001b[0;31m         return parallel_apply(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":41},{"cell_type":"markdown","source":"**Different Hyperparameters**","metadata":{}},{"cell_type":"code","source":"!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n!tar -xf abo-images-small.tar\n!rm abo-images-small.tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T13:53:24.775544Z","iopub.execute_input":"2025-05-17T13:53:24.775829Z","iopub.status.idle":"2025-05-17T13:54:50.668607Z","shell.execute_reply.started":"2025-05-17T13:53:24.775807Z","shell.execute_reply":"2025-05-17T13:54:50.667312Z"}},"outputs":[{"name":"stdout","text":"--2025-05-17 13:53:24--  https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\nResolving amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)... 3.5.22.67, 3.5.27.123, 52.216.60.49, ...\nConnecting to amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)|3.5.22.67|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3253381120 (3.0G) [application/x-tar]\nSaving to: ‘abo-images-small.tar’\n\nabo-images-small.ta 100%[===================>]   3.03G  55.5MB/s    in 61s     \n\n2025-05-17 13:54:25 (51.3 MB/s) - ‘abo-images-small.tar’ saved [3253381120/3253381120]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pickle\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:07:31.487477Z","iopub.execute_input":"2025-05-17T14:07:31.487804Z","iopub.status.idle":"2025-05-17T14:08:20.011052Z","shell.execute_reply.started":"2025-05-17T14:07:31.487769Z","shell.execute_reply":"2025-05-17T14:08:20.010359Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 14:07:59.545094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747490880.073208      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747490880.215208      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"with open(\"/kaggle/input/train-data/train.json\", \"r\") as f:\n    questions_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:09.031114Z","iopub.execute_input":"2025-05-17T14:36:09.031458Z","iopub.status.idle":"2025-05-17T14:36:09.072128Z","shell.execute_reply.started":"2025-05-17T14:36:09.031418Z","shell.execute_reply":"2025-05-17T14:36:09.071209Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:09.619049Z","iopub.execute_input":"2025-05-17T14:36:09.619363Z","iopub.status.idle":"2025-05-17T14:36:09.624346Z","shell.execute_reply.started":"2025-05-17T14:36:09.619330Z","shell.execute_reply":"2025-05-17T14:36:09.623584Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"all_entries = []\nfor img_path, qas in list(questions_data.items()):\n    for qa in qas:\n        all_entries.append({\n            \"image_path\": img_path,\n            \"question\": qa[\"question\"],\n            \"answer\": qa[\"answer\"]\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:10.980710Z","iopub.execute_input":"2025-05-17T14:36:10.980986Z","iopub.status.idle":"2025-05-17T14:36:11.008901Z","shell.execute_reply.started":"2025-05-17T14:36:10.980967Z","shell.execute_reply":"2025-05-17T14:36:11.008126Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"train_data, val_data = train_test_split(all_entries, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:12.409959Z","iopub.execute_input":"2025-05-17T14:36:12.410688Z","iopub.status.idle":"2025-05-17T14:36:12.424419Z","shell.execute_reply.started":"2025-05-17T14:36:12.410657Z","shell.execute_reply":"2025-05-17T14:36:12.423449Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"class CustomVQADataset(Dataset):\n    def __init__(self, data, processor):\n        self.data = data\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        image = Image.open(item[\"image_path\"]).convert(\"RGB\")\n        question = item[\"question\"]\n        answer = item[\"answer\"].lower()\n\n        # Process the image and question\n        encoding = self.processor(image, question, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        labels = self.processor.tokenizer.encode(answer, max_length=8, padding=\"max_length\", truncation=True, return_tensors='pt')\n\n        encoding[\"labels\"] = labels\n        for k, v in encoding.items():\n            encoding[k] = v.squeeze(0)\n\n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:16.656424Z","iopub.execute_input":"2025-05-17T14:36:16.656752Z","iopub.status.idle":"2025-05-17T14:36:16.663313Z","shell.execute_reply.started":"2025-05-17T14:36:16.656730Z","shell.execute_reply":"2025-05-17T14:36:16.662329Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nbase_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# Apply LoRA\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=0.2,\n    bias=\"none\",\n)\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:18.284254Z","iopub.execute_input":"2025-05-17T14:36:18.284579Z","iopub.status.idle":"2025-05-17T14:36:19.818877Z","shell.execute_reply.started":"2025-05-17T14:36:18.284554Z","shell.execute_reply":"2025-05-17T14:36:19.817954Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,359,296 || all params: 387,031,868 || trainable%: 0.6096\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"train_dataset = CustomVQADataset(train_data, processor)\nval_dataset = CustomVQADataset(val_data, processor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:20.478557Z","iopub.execute_input":"2025-05-17T14:36:20.478861Z","iopub.status.idle":"2025-05-17T14:36:20.504470Z","shell.execute_reply.started":"2025-05-17T14:36:20.478840Z","shell.execute_reply":"2025-05-17T14:36:20.503205Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.nn.DataParallel(model)\nmodel.to(device)\n\n# Optimizer: AdamW with weight decay\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:36:22.012629Z","iopub.execute_input":"2025-05-17T14:36:22.013137Z","iopub.status.idle":"2025-05-17T14:36:22.629320Z","shell.execute_reply.started":"2025-05-17T14:36:22.013110Z","shell.execute_reply":"2025-05-17T14:36:22.628673Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Scheduler: Warmup + Linear Decay\nnum_epochs = 30\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * total_steps),   # Warmup = 10% of training steps\n    num_training_steps=total_steps\n)\n\n# Mixed precision scaler\nscaler = torch.cuda.amp.GradScaler()\n\npatience = 3\nmin_eval_loss = float(\"inf\")\nearly_stopping = 0\ntracking = []\n\nfor epoch in range(1, num_epochs):\n    model.train()\n    train_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch} Training\"):\n        input_ids = batch['input_ids'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(input_ids=input_ids,\n                            pixel_values=pixel_values,\n                            attention_mask=attention_mask,\n                            labels=labels)\n        loss = outputs.loss\n        if loss.ndim > 0:\n            loss = loss.mean()\n        train_loss += loss.item()\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()  # Moved here: step scheduler after each optimizer step\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Validating\"):\n            input_ids = batch['input_ids'].to(device)\n            pixel_values = batch['pixel_values'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = model(input_ids=input_ids,\n                                pixel_values=pixel_values,\n                                attention_mask=attention_mask,\n                                labels=labels)\n            loss = outputs.loss\n            if loss.ndim > 0:\n                loss = loss.mean()\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(val_loader)\n    tracking.append((train_loss, val_loss))\n\n    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n\n    # Early stopping\n    if val_loss < min_eval_loss:\n        min_eval_loss = val_loss\n        early_stopping = 0\n        model.module.save_pretrained(\"blip-lora-vqa\")\n        shutil.make_archive(\"blip-lora-vqa\", 'zip', \"blip-lora-vqa\")\n        print(\"Saved best model.\")\n    else:\n        early_stopping += 1\n        if early_stopping >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\nwith open(\"training_tracking.pkl\", \"wb\") as f:\n    pickle.dump(tracking, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:10:12.460316Z","iopub.execute_input":"2025-05-17T19:10:12.460667Z","iopub.status.idle":"2025-05-17T19:10:19.380597Z","shell.execute_reply.started":"2025-05-17T19:10:12.460644Z","shell.execute_reply":"2025-05-17T19:10:19.376541Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4011087373.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\nEpoch 1 Training:   0%|          | 7/3053 [00:06<49:45,  1.02it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4011087373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             outputs = model(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     30\u001b[0m                             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     ) -> List[Any]:\n\u001b[0;32m--> 212\u001b[0;31m         return parallel_apply(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}